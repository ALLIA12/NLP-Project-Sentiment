{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "id": "KK7cgNMRftMM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "#from google.colab import drive\n",
    "import pickle\n",
    "import lxml"
   ],
   "metadata": {
    "id": "WeQeHuFpfvIU",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:30.411584900Z",
     "start_time": "2024-02-12T11:35:29.902686Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ],
   "metadata": {
    "id": "ojoSB8r1gSZl",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:34.028778600Z",
     "start_time": "2024-02-12T11:35:30.412587600Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:34.045254500Z",
     "start_time": "2024-02-12T11:35:34.030778900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:34.072137900Z",
     "start_time": "2024-02-12T11:35:34.047255Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load files"
   ],
   "metadata": {
    "id": "4zlEVP0nlaju"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDqbjubnlcQ9",
    "outputId": "a5b531a6-0e8a-4b0c-9db3-a94348387fb8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "pkAOXuzulumg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cols =['sentiment','id','date','query','user','text']\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"NLP-Project-Sentiment/training.1600000.processed.noemoticon.csv\",\n",
    "    header=None,\n",
    "    names=cols,\n",
    "    engine='python',\n",
    "    encoding='latin1'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:49.897092200Z",
     "start_time": "2024-02-12T11:35:38.247948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data.head(3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Z9jPx71rm64o",
    "outputId": "29df8392-e201-4b9c-e788-7d8e774828cf",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:49.965563600Z",
     "start_time": "2024-02-12T11:35:49.908147200Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment          id                          date     query  \\\n0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>id</th>\n      <th>date</th>\n      <th>query</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre process data"
   ],
   "metadata": {
    "id": "PCX4ZzQLnORI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data.drop(['id','date','query','user'],axis=1,inplace=True)"
   ],
   "metadata": {
    "id": "tjBgQKaZnRD4",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:50.047112500Z",
     "start_time": "2024-02-12T11:35:49.955564500Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "0BfY30g5ngsS",
    "outputId": "77aafb35-fb41-49a8-fb97-c48aa5fc66be",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:50.081114200Z",
     "start_time": "2024-02-12T11:35:50.003573100Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   sentiment                                               text\n0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1          0  is upset that he can't update his Facebook by ...\n2          0  @Kenichan I dived many times for the ball. Man...\n3          0    my whole body feels itchy and like its on fire \n4          0  @nationwideclass no, it's not behaving at all....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def cleanText(text):\n",
    "  text = BeautifulSoup(text,'html.parser').get_text()\n",
    "  text = re.sub(r'@[A-za-z0-9]+',\" \",text)\n",
    "  text = re.sub(r'https?://[A-za-z0-9./]+',' ',text)\n",
    "  text = re.sub(r'[^a-zA-Z.!?]',' ',text)\n",
    "  text = re.sub(r' +',\" \",text)\n",
    "  return text"
   ],
   "metadata": {
    "id": "n5ssaQU6nmOb",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:35:50.081114200Z",
     "start_time": "2024-02-12T11:35:50.020115900Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean the text"
   ],
   "metadata": {
    "id": "skiHRm4QE7O1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_clean = [cleanText(text) for text in data.text]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXJvm6heqHhk",
    "outputId": "bd2c627c-e715-4141-d2ab-6921cd636ed0",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:03.872363Z",
     "start_time": "2024-02-12T11:35:50.035113400Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thehi\\AppData\\Local\\Temp\\ipykernel_18424\\1337334217.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text,'html.parser').get_text()\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[' Awww that s a bummer. You shoulda got David Carr of Third Day to do it. D',\n 'is upset that he can t update his Facebook by texting it... and might cry as a result School today also. Blah!',\n ' I dived many times for the ball. Managed to save The rest go out of bounds',\n 'my whole body feels itchy and like its on fire ',\n ' no it s not behaving at all. i m mad. why am i here? because I can t see you all over there. ']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:03.893647600Z",
     "start_time": "2024-02-12T11:37:03.873474600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean Labels\n",
    "0 is Positive\n",
    "\n",
    "1 is Negative"
   ],
   "metadata": {
    "id": "t8LasNyREgLf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_labels = data.sentiment.values\n",
    "data_labels[data_labels==4] = 1\n",
    "set(data_labels)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR6oMbF8B9Q3",
    "outputId": "a31fc3ac-7904-4c3f-a7ae-3cc179e5628e",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:03.988674Z",
     "start_time": "2024-02-12T11:37:03.893647600Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{0, 1}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "id": "9ZCXKaywFNlN"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "loi51fPpn9bq",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:04.002355100Z",
     "start_time": "2024-02-12T11:37:03.986677Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Dzki1rb5FQC1",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:04.046358Z",
     "start_time": "2024-02-12T11:37:04.004328600Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the tokenizer from a file\n",
    "with open('NLP-Project-Sentiment/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:04.224436Z",
     "start_time": "2024-02-12T11:37:04.021324700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=2**16, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data_clean)\n",
    "# Save the tokenizer to a file\n",
    "with open('NLP-Project-Sentiment/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sequences = tokenizer.texts_to_sequences(data_clean)\n",
    "data_inputs =sequences"
   ],
   "metadata": {
    "id": "KMu91iRVGP9b",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:21.429646800Z",
     "start_time": "2024-02-12T11:37:04.224436Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Padding\n",
    "Add 0 for all sentences to match maximum length of each sentence after it was tokenized"
   ],
   "metadata": {
    "id": "oD3bOfdlH9Uf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_LENGTH = max([len(sentence) for sentence in data_inputs])\n",
    "data_inputs= tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    data_inputs,\n",
    "    value=0,\n",
    "    padding=\"post\",\n",
    "    maxlen=MAX_LENGTH\n",
    ")"
   ],
   "metadata": {
    "id": "q3LxFLkbH_P_",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.016460600Z",
     "start_time": "2024-02-12T11:37:21.430650100Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(MAX_LENGTH)\n",
    "data_inputs[:5]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b94TAQ5pM6do",
    "outputId": "2b3a620a-a38b-4893-b7ec-b39b623feaed",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.031461500Z",
     "start_time": "2024-02-12T11:37:25.018461300Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[  445,    17,    13,     5,  1174,     9,  3429,    50,   836,\n         9439,    15,  1864,    34,     3,    43,     7,   140,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0],\n       [   10,   781,    17,    85,    31,    14,   544,   184,   532,\n          124,  1992,     7,     8,   290,   528,    84,     5,  2301,\n          144,    42,   266,  1117,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0],\n       [    2, 51831,   314,   351,    12,     4,  1228,  1659,     3,\n          896,     4,   468,    41,    36,    15, 22589,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0],\n       [    6,   427,   801,   480,  2868,     8,    38,    69,    16,\n         1143,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0],\n       [   40,     7,    13,    27, 10043,    26,    35,     2,    21,\n          594,   111,    54,     2,    87,   208,     2,    31,    14,\n           66,     9,    35,   132,    68,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Data into Train/Test"
   ],
   "metadata": {
    "id": "aHvpTyJGJM1q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_idx = np.random.randint(0,800000,8000)\n",
    "test_idx = np.concatenate((test_idx,test_idx+800000))"
   ],
   "metadata": {
    "id": "2npuFQA0JPK6",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.091834300Z",
     "start_time": "2024-02-12T11:37:25.033462Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_inputs = data_inputs[test_idx]\n",
    "test_labels = data_labels[test_idx]"
   ],
   "metadata": {
    "id": "PGHlSIRFKx5C",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.096833300Z",
     "start_time": "2024-02-12T11:37:25.054320Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_inputs = np.delete(data_inputs,test_idx,axis=0)\n",
    "train_labels = np.delete(data_labels,test_idx)"
   ],
   "metadata": {
    "id": "eFbZArAhLBoU",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.190278500Z",
     "start_time": "2024-02-12T11:37:25.064319600Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the model"
   ],
   "metadata": {
    "id": "YnDJjhzePSU3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DeepCNN(tf.keras.Model):\n",
    "  def __init__(self,\n",
    "               vocab_size,\n",
    "               emb_dim=128,\n",
    "               nb_filters=50,\n",
    "               FFN_units=512,\n",
    "               nb_classes=2,\n",
    "               dropout_rate=0.1,\n",
    "               training=False,\n",
    "               name=\"DeepCNN\",\n",
    "               ):\n",
    "    super(DeepCNN,self).__init__(name=name)\n",
    "    self.embedding= layers.Embedding(vocab_size,\n",
    "                                      emb_dim)\n",
    "    self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                kernel_size=2,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")\n",
    "    self.pool_1= layers.GlobalMaxPool1D()\n",
    "    self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                kernel_size=3,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")\n",
    "    self.pool_2= layers.GlobalMaxPool1D()\n",
    "    self.quadgram = layers.Conv1D(filters=nb_filters,\n",
    "                                kernel_size=4,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")\n",
    "    self.pool_3= layers.GlobalMaxPool1D()\n",
    "    self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "    self.dropout = layers.Dropout(rate = dropout_rate)\n",
    "    if nb_classes == 2:\n",
    "      self.last_dense = layers.Dense(units=1,activation=\"sigmoid\")\n",
    "    else:\n",
    "      # You will need to get the maximum probablity later\n",
    "      self.last_dense = layers.Dense(units=nb_classes,activation=\"softmax\")\n",
    "\n",
    "  def call(self,inputs,training):\n",
    "    x = self.embedding(inputs)\n",
    "    x_1 = self.bigram(x)\n",
    "    x_1 = self.pool_1(x_1)\n",
    "    x_2 = self.trigram(x)\n",
    "    x_2 = self.pool_2(x_2)\n",
    "    x_3 = self.quadgram(x)\n",
    "    x_3 = self.pool_3(x_3)\n",
    "\n",
    "    merged = tf.concat([x_1,x_2,x_3],axis=-1) # something like this (batchsize, 3*nb_filters)\n",
    "    merged = self.dense_1(merged)\n",
    "    merged = self.dropout(merged,training)\n",
    "    output = self.last_dense(merged)\n",
    "    return output\n",
    "\n"
   ],
   "metadata": {
    "id": "GUMTOPm8PVQe",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.229045500Z",
     "start_time": "2024-02-12T11:37:25.193271800Z"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Where the magic happens"
   ],
   "metadata": {
    "id": "UcvatzMSTT2B"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {
    "id": "ZYEYjmmBTYnC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index)\n",
    "\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES= len(set(train_labels))\n",
    "\n",
    "DROUPOUT_RATE = 0.2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 1"
   ],
   "metadata": {
    "id": "Cl-ylproTwCj",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.306512400Z",
     "start_time": "2024-02-12T11:37:25.222019400Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "id": "blDHZQcIULyJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "deepCNN = DeepCNN(vocab_size=VOCAB_SIZE,\n",
    "                  emb_dim=EMB_DIM,\n",
    "                  nb_filters=NB_FILTERS,\n",
    "                  FFN_units=FFN_UNITS,\n",
    "                  nb_classes=NB_CLASSES,\n",
    "                  dropout_rate=DROUPOUT_RATE,\n",
    "                  )"
   ],
   "metadata": {
    "id": "xGqpP1v-UNVc",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.354708100Z",
     "start_time": "2024-02-12T11:37:25.308475100Z"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if NB_CLASSES ==2:\n",
    "  deepCNN.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"]\n",
    "                  )\n",
    "else:\n",
    "  deepCNN.compiler(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=\"adam\",\n",
    "                   metrics=[\"sparse_categorical_accuracy\"]\n",
    "                   )"
   ],
   "metadata": {
    "id": "kGDOa6OhU5ji",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.397451500Z",
     "start_time": "2024-02-12T11:37:25.357673600Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fT5A3TWkVoWQ",
    "outputId": "3f5effc8-6ecf-4bac-fccc-9ece1d4dab8d",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.404417200Z",
     "start_time": "2024-02-12T11:37:25.387420300Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Checkpoint restored\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"NLP-Project-Sentiment\"\n",
    "ckpt = tf.train.Checkpoint(deepCNN=deepCNN)\n",
    "ckpt_manager=tf.train.CheckpointManager(ckpt,checkpoint_path,max_to_keep=1)\n",
    "\n",
    "if(ckpt_manager.latest_checkpoint):\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print(\"Latest Checkpoint restored\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.463489500Z",
     "start_time": "2024-02-12T11:37:25.403417400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.508731700Z",
     "start_time": "2024-02-12T11:37:25.465492100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:37:25.512697500Z",
     "start_time": "2024-02-12T11:37:25.482582600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "deepCNN.fit(train_inputs,train_labels,batch_size=BATCH_SIZE,epochs=NB_EPOCHS)\n",
    "ckpt_manager.save()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifcsLX_jWX7V",
    "outputId": "aefb4257-42ea-479b-be62-000e9da52f52",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:07.657846200Z",
     "start_time": "2024-02-12T11:37:25.495696400Z"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1683/49503 [>.............................] - ETA: 5:58:37 - loss: 0.1229 - accuracy: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "id": "nrq22GjEY80d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results = deepCNN.evaluate(test_inputs,test_labels,batch_size=BATCH_SIZE)\n",
    "print(results)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FGj5NqvZAZj",
    "outputId": "7a584875-af96-4376-dea6-322625d4617e",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:15.540225700Z",
     "start_time": "2024-02-12T11:50:13.642577800Z"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.1246 - accuracy: 0.9521\n",
      "[0.12464036792516708, 0.9521250128746033]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# User Input"
   ],
   "metadata": {
    "id": "9SzS84ZuZ7bo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def processInput(text):\n",
    "    # Convert the input text to sequence\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "    # Predict using the sequence\n",
    "    prediction = deepCNN(np.array(padded_sequence ), training=False)\n",
    "    # Convert model's output to a user-friendly result\n",
    "    if prediction >= 0.5:\n",
    "        return f\"The result is Positive, {prediction} confidence\"\n",
    "    else:\n",
    "        return f\"The result is Negative, {1-prediction} confidence\""
   ],
   "metadata": {
    "id": "PkJAWOAnaAOb",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:17.513561400Z",
     "start_time": "2024-02-12T11:50:17.398089900Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This cell will be run to take user input and display the result\n",
    "\n",
    "# Take user input\n",
    "user_text = input(\"Please enter your text: \")\n",
    "\n",
    "# Process the input and display the result\n",
    "result = processInput(user_text)\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtXniwEnZr2K",
    "outputId": "976fd980-9d58-4a27-e53e-485dd36a717d",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:19.819968700Z",
     "start_time": "2024-02-12T11:50:18.427561100Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is Negative, [[0.5554429]] confidence\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assume deepCNN is your model and it's correctly defined and restored from checkpoint\n",
    "model_dir = 'sentiment_analysis_model'  # Directory to save the exported model\n",
    "\n",
    "# Save the model in SavedModel format\n",
    "tf.saved_model.save(ckpt.deepCNN, model_dir)"
   ],
   "metadata": {
    "id": "2192RediqbSY",
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:23.248577900Z",
     "start_time": "2024-02-12T11:50:21.289814900Z"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sentiment_analysis_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sentiment_analysis_model\\assets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
